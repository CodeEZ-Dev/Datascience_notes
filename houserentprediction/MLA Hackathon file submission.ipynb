{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score,mean_absolute_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID             area_type   availability                  location  \\\n",
      "0   0  Super built-up  Area         19-Dec  Electronic City Phase II   \n",
      "1   1            Plot  Area  Ready To Move          Chikka Tirupathi   \n",
      "2   2        Built-up  Area  Ready To Move               Uttarahalli   \n",
      "3   3  Super built-up  Area  Ready To Move        Lingadheeranahalli   \n",
      "4   4  Super built-up  Area  Ready To Move                  Kothanur   \n",
      "\n",
      "        size  society total_sqft  bath  balcony   price  \n",
      "0      2 BHK  Coomee        1056   2.0      1.0   39.07  \n",
      "1  4 Bedroom  Theanmp       2600   5.0      3.0  120.00  \n",
      "2      3 BHK      NaN       1440   2.0      3.0   62.00  \n",
      "3      3 BHK  Soiewre       1521   3.0      1.0   95.00  \n",
      "4      2 BHK      NaN       1200   2.0      1.0   51.00  \n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "avg_rent = pd.read_csv('./data/avg_rent.csv')\n",
    "dist_city = pd.read_csv('./data/dist_from_city_centre.csv')\n",
    "\n",
    "print(train.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge external data\n",
    "train = train.merge(avg_rent, on='location', how='left')\n",
    "train = train.merge(dist_city, on='location', how='left')\n",
    "\n",
    "test = test.merge(avg_rent, on='location', how='left')\n",
    "test = test.merge(dist_city, on='location', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Handle missing values\n",
    "train.fillna({'bath': train['bath'].median(), 'balcony': 0, 'avg_2bhk_rent': 0, 'dist_from_city': train['dist_from_city'].median()}, inplace=True)\n",
    "test.fillna({'bath': test['bath'].median(), 'balcony': 0, 'avg_2bhk_rent': 0, 'dist_from_city': test['dist_from_city'].median()}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to convert 'total_sqft' to a numeric value\n",
    "def convert_sqft_to_num(sqft):\n",
    "    try:\n",
    "        # Handle ranges (e.g., \"2100 - 2850\")\n",
    "        if '-' in sqft:\n",
    "            sqft_range = sqft.split('-')\n",
    "            return (float(sqft_range[0]) + float(sqft_range[1])) / 2  # Average of the range\n",
    "        \n",
    "        # Ignore strings containing keywords (e.g., \"Super built-up Area\")\n",
    "        if any(keyword in sqft.lower() for keyword in ['built-up', 'super', 'carpet', 'area']):\n",
    "            return np.nan\n",
    "        \n",
    "        # Handle purely numeric values\n",
    "        if sqft.replace('.', '', 1).isdigit():\n",
    "            return float(sqft)\n",
    "        \n",
    "        # Extract numeric values from text (e.g., \"2100 sqft\")\n",
    "        sqft_numeric = re.findall(r'\\d+\\.?\\d*', sqft)\n",
    "        if sqft_numeric:\n",
    "            return float(sqft_numeric[0])  # Take the first numeric part\n",
    "        \n",
    "        return np.nan  # Return NaN for unhandled cases\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting '{sqft}': {e}\")\n",
    "        return np.nan  # Fallback for unexpected issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the updated function to total_sqft\n",
    "train['total_sqft'] = train['total_sqft'].astype(str).apply(convert_sqft_to_num)\n",
    "test['total_sqft'] = test['total_sqft'].astype(str).apply(convert_sqft_to_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Handle missing or invalid values (if any rows have NaN after conversion)\n",
    "train['total_sqft'].fillna(train['total_sqft'].median(), inplace=True)\n",
    "test['total_sqft'].fillna(test['total_sqft'].median(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Feature engineering for train data\n",
    "train['num_bedrooms'] = train['size'].str.extract('(\\d+)').astype(float)\n",
    "train['price_per_sqft'] = train['price'] / train['total_sqft']\n",
    "train['rent_to_price_ratio'] = train['avg_2bhk_rent'] / train['price']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Feature engineering for test data (no price-related features)\n",
    "test['num_bedrooms'] = test['size'].str.extract('(\\d+)').astype(float)\n",
    "test['price_per_sqft'] = test['total_sqft']  # Placeholder for testing, since we don't have price\n",
    "test['rent_to_price_ratio'] = test['avg_2bhk_rent']  # Placeholder for testing, since we don't have price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove any remaining invalid entries in the dataset\n",
    "train.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split data\n",
    "X = train.drop(columns=['price','ID'])\n",
    "y = train['price']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Identify categorical columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Create a preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), X.select_dtypes(exclude=['object']).columns),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Create a pipeline with preprocessing and model training\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Define model\n",
    "# model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# # Hyperparameter tuning using GridSearchCV\n",
    "# param_grid = {\n",
    "#     'n_estimators': [100, 200, 500],\n",
    "#     'max_depth': [None, 10, 20, 30],\n",
    "#     'min_samples_split': [2, 5, 10],\n",
    "#     'min_samples_leaf': [1, 2, 4]\n",
    "# }\n",
    "# grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', verbose=1, n_jobs=-1)\n",
    "\n",
    "# pipeline = Pipeline(steps=[\n",
    "#     ('preprocessor', preprocessor),\n",
    "#     ('model', grid_search)\n",
    "# ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 27.181167018514568\n",
      "Validation MAE: 2.8293075562700962\n",
      "Validation R²: 0.9416365875706646\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Split data for training\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = pipeline.predict(X_val)\n",
    "rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "print(f\"Validation RMSE: {rmse}\")\n",
    "print(f\"Validation MAE: {mae}\")\n",
    "print(f\"Validation R²: {r2}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions have been saved to 'submission.csv'\n"
     ]
    }
   ],
   "source": [
    "# Handle missing values in the test set (Impute missing values)\n",
    "# Create an imputer for numerical columns\n",
    "num_imputer = SimpleImputer(strategy='mean')  # You can also use 'median' or 'most_frequent' based on your preference\n",
    "cat_imputer = SimpleImputer(strategy='most_frequent')  # For categorical columns, we can impute the most frequent value\n",
    "\n",
    "# Apply the imputers to the test set before prediction\n",
    "numerical_cols = test.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_cols = test.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Impute missing numerical data\n",
    "test[numerical_cols] = num_imputer.fit_transform(test[numerical_cols])\n",
    "\n",
    "# Impute missing categorical data\n",
    "test[categorical_cols] = cat_imputer.fit_transform(test[categorical_cols])\n",
    "\n",
    "# Ensure 'ID' column is dropped before prediction\n",
    "test_processed = test.drop(columns=['ID'])\n",
    "\n",
    "# Predict on test data\n",
    "test_pred = pipeline.predict(test_processed)\n",
    "\n",
    "# Save predictions with ID as integer\n",
    "test['price'] = test_pred\n",
    "\n",
    "# Convert 'ID' column to integer type before saving\n",
    "test['ID'] = test['ID'].astype(int)\n",
    "\n",
    "# Save the predictions to 'submission.csv'\n",
    "test[['ID','price']].to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"Predictions have been saved to 'submission.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
